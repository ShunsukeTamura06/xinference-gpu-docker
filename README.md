# Xinference GPU Docker Setup

AWS GPUæ­è¼‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆarm64ï¼‰ä¸Šã§Dockerã‚’ä½¿ç”¨ã—ã¦amd64ç’°å¢ƒã§Xinferenceã‚µãƒ¼ãƒãƒ¼ã‚’GPUå¯¾å¿œã§å‹•ä½œã•ã›ã‚‹ãŸã‚ã®è¨­å®šã§ã™ã€‚ãƒ—ãƒ­ã‚­ã‚·ç’°å¢ƒã§ã®ä½¿ç”¨ã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚

## ğŸ“‹ å‰ææ¡ä»¶

- AWS GPUæ­è¼‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆä¾‹ï¼šg4dn.xlarge, p3.2xlarge ãªã©ï¼‰
- Ubuntu 20.04+ ã¾ãŸã¯ Amazon Linux 2
- Docker ã¨ Docker Compose ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
- NVIDIA GPU ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
- ä¼æ¥­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒã®å ´åˆã¯ãƒ—ãƒ­ã‚­ã‚·è¨­å®š

## ğŸŒ ãƒ—ãƒ­ã‚­ã‚·ç’°å¢ƒã§ã®è¨­å®š

ä¼æ¥­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒã®å ´åˆã€ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’è¡Œã£ã¦ãã ã•ã„ï¼š

### 1. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

```bash
export HTTP_PROXY=http://hn02-outbound.gm.internal:8080
export HTTPS_PROXY=http://hn02-outbound.gm.internal:8080
export http_proxy=http://hn02-outbound.gm.internal:8080
export https_proxy=http://hn02-outbound.gm.internal:8080
export NO_PROXY=localhost,127.0.0.1,.internal,.local
export no_proxy=localhost,127.0.0.1,.internal,.local
```

### 2. æ°¸ç¶šåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

```bash
# ~/.bashrcã«è¿½åŠ 
echo 'export HTTP_PROXY=http://hn02-outbound.gm.internal:8080' >> ~/.bashrc
echo 'export HTTPS_PROXY=http://hn02-outbound.gm.internal:8080' >> ~/.bashrc
source ~/.bashrc
```

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³

```bash
git clone https://github.com/ShunsukeTamura06/xinference-gpu-docker.git
cd xinference-gpu-docker
```

### 2. ãƒ—ãƒ­ã‚­ã‚·è¨­å®šï¼ˆä¼æ¥­ç’°å¢ƒã®å ´åˆï¼‰

```bash
# ãƒ—ãƒ­ã‚­ã‚·è¨­å®š
export HTTP_PROXY=http://hn02-outbound.gm.internal:8080
export HTTPS_PROXY=http://hn02-outbound.gm.internal:8080
```

### 3. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ

```bash
chmod +x setup.sh
./setup.sh
```

### 4. Xinferenceã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•

```bash
docker compose up -d
```

### 5. å‹•ä½œç¢ºèª

```bash
# ãƒ­ã‚°ã®ç¢ºèª
docker compose logs -f xinference

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:9997/health
```

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
xinference-gpu-docker/
â”œâ”€â”€ Dockerfile              # Xinference GPUç”¨Dockerãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ—ãƒ­ã‚­ã‚·å¯¾å¿œï¼‰
â”œâ”€â”€ docker-compose.yml      # Docker Composeè¨­å®šï¼ˆãƒ—ãƒ­ã‚­ã‚·è¨­å®šå«ã‚€ï¼‰
â”œâ”€â”€ setup.sh               # ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ models/                # ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
â”œâ”€â”€ logs/                  # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
â””â”€â”€ README.md              # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

## ğŸ”§ è¨­å®šã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã®å¤‰æ›´

`docker-compose.yml`ã§ãƒ—ãƒ­ã‚­ã‚·URLã‚’å¤‰æ›´ï¼š

```yaml
args:
  HTTP_PROXY: http://your-proxy:port
  HTTPS_PROXY: http://your-proxy:port
```

### ãƒãƒ¼ãƒˆç•ªå·ã®å¤‰æ›´

`docker-compose.yml`ã®`ports`ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç·¨é›†ï¼š

```yaml
ports:
  - "YOUR_PORT:9997"
```

### GPUè¨­å®šã®å¤‰æ›´

è¤‡æ•°GPUã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€`docker-compose.yml`ã‚’ç·¨é›†ï¼š

```yaml
environment:
  - CUDA_VISIBLE_DEVICES=0,1  # ä½¿ç”¨ã™ã‚‹GPUç•ªå·
```

### ãƒ¡ãƒ¢ãƒªåˆ¶é™ã®è¨­å®š

```yaml
deploy:
  resources:
    limits:
      memory: 8G
```

## ğŸ“Š ä½¿ç”¨æ–¹æ³•

### Xinference Web UI ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹

ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://YOUR_SERVER_IP:9997` ã«ã‚¢ã‚¯ã‚»ã‚¹

### APIçµŒç”±ã§ã®åˆ©ç”¨

```bash
# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
curl http://localhost:9997/v1/models

# ãƒ¢ãƒ‡ãƒ«ã®èµ·å‹•ä¾‹
curl -X POST http://localhost:9997/v1/models \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "vicuna-v1.3",
    "model_size_in_billions": 7
  }'
```

### Python ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ã®åˆ©ç”¨

```python
from xinference.client import Client

client = Client("http://localhost:9997")

# ãƒ¢ãƒ‡ãƒ«ã®èµ·å‹•
model = client.launch_model(
    model_name="vicuna-v1.3",
    model_size_in_billions=7
)

# æ¨è«–ã®å®Ÿè¡Œ
response = model.chat(
    "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ"
)
print(response)
```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ãƒ—ãƒ­ã‚­ã‚·é–¢é€£ã‚¨ãƒ©ãƒ¼

#### ãƒ“ãƒ«ãƒ‰æ™‚ã«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚¨ãƒ©ãƒ¼

```bash
# ãƒ—ãƒ­ã‚­ã‚·è¨­å®šç¢ºèª
echo $HTTP_PROXY

# æ‰‹å‹•ã§ãƒ—ãƒ­ã‚­ã‚·è¨­å®š
export HTTP_PROXY=http://hn02-outbound.gm.internal:8080
export HTTPS_PROXY=http://hn02-outbound.gm.internal:8080

# å†ãƒ“ãƒ«ãƒ‰
docker compose build --no-cache
```

#### apt-getã‚¨ãƒ©ãƒ¼

```bash
# Dockerå†…ã§aptç”¨ãƒ—ãƒ­ã‚­ã‚·è¨­å®šç¢ºèª
docker compose build --progress=plain
```

### GPUèªè­˜ã•ã‚Œãªã„å ´åˆ

```bash
# GPUç¢ºèª
nvidia-smi

# NVIDIA Container Toolkitç¢ºèª
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu20.04 nvidia-smi
```

### ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹ã‹ã€ã‚ˆã‚Šå¤§ããªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã‚’ä½¿ç”¨ï¼š

```bash
# ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
docker stats xinference-gpu-docker-xinference-1
```

### arm64ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚¨ãƒ©ãƒ¼

`docker-compose.yml`ã§æ˜ç¤ºçš„ã«amd64ã‚’æŒ‡å®šï¼š

```yaml
platform: linux/amd64
```

### ãƒãƒ¼ãƒˆè¡çª

åˆ¥ã®ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨ï¼š

```yaml
ports:
  - "9998:9997"  # 9998ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. SHMã‚µã‚¤ã‚ºã®å¢—åŠ 

```yaml
shm_size: '2g'
```

### 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®æœ€é©åŒ–

SSDã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ä½¿ç”¨ã‚’æ¨å¥¨ï¼š

```yaml
volumes:
  - /mnt/ssd/models:/root/.xinference/cache
```

### 3. ä¸¦åˆ—å‡¦ç†ã®è¨­å®š

```yaml
environment:
  - OMP_NUM_THREADS=4
  - XINFERENCE_MODEL_CACHE_SIZE=10
```

## ğŸ› ï¸ ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§

| ã‚³ãƒãƒ³ãƒ‰ | èª¬æ˜ |
|---------|------|
| `docker compose up -d` | ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰ |
| `docker compose down` | ã‚µãƒ¼ãƒãƒ¼åœæ­¢ |
| `docker compose logs -f` | ãƒ­ã‚°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º |
| `docker compose ps` | ã‚³ãƒ³ãƒ†ãƒŠçŠ¶æ…‹ç¢ºèª |
| `docker compose restart` | ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹• |
| `docker compose pull` | ã‚¤ãƒ¡ãƒ¼ã‚¸æ›´æ–° |
| `docker compose build --no-cache` | å¼·åˆ¶å†ãƒ“ãƒ«ãƒ‰ |

## ğŸ†˜ ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆï¼š

1. [Issues](https://github.com/ShunsukeTamura06/xinference-gpu-docker/issues) ã§æ—¢å­˜ã®å•é¡Œã‚’ç¢ºèª
2. æ–°ã—ã„Issueã‚’ä½œæˆï¼ˆãƒ­ã‚°ã¨ç’°å¢ƒæƒ…å ±ã‚’å«ã‚ã‚‹ï¼‰
3. [Xinferenceå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://inference.readthedocs.io/) ã‚’å‚ç…§

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚„Issueã¯æ­“è¿ã—ã¾ã™ï¼