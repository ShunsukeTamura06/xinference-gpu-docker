# Xinference GPU Docker Setup

AWS GPUæ­è¼‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆarm64ï¼‰ä¸Šã§Dockerã‚’ä½¿ç”¨ã—ã¦amd64ç’°å¢ƒã§Xinferenceã‚µãƒ¼ãƒãƒ¼ã‚’GPUå¯¾å¿œã§å‹•ä½œã•ã›ã‚‹ãŸã‚ã®è¨­å®šã§ã™ã€‚

## ğŸ“‹ å‰ææ¡ä»¶

- AWS GPUæ­è¼‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆä¾‹ï¼šg4dn.xlarge, p3.2xlarge ãªã©ï¼‰
- Ubuntu 20.04+ ã¾ãŸã¯ Amazon Linux 2
- Docker ã¨ Docker Compose ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
- NVIDIA GPU ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³

```bash
git clone https://github.com/ShunsukeTamura06/xinference-gpu-docker.git
cd xinference-gpu-docker
```

### 2. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ

```bash
chmod +x setup.sh
./setup.sh
```

### 3. Xinferenceã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•

```bash
docker-compose up -d
```

### 4. å‹•ä½œç¢ºèª

```bash
# ãƒ­ã‚°ã®ç¢ºèª
docker-compose logs -f xinference

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:9997/health
```

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
xinference-gpu-docker/
â”œâ”€â”€ Dockerfile              # Xinference GPUç”¨Dockerãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ docker-compose.yml      # Docker Composeè¨­å®š
â”œâ”€â”€ setup.sh               # ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ models/                # ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
â”œâ”€â”€ logs/                  # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
â””â”€â”€ README.md              # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

## ğŸ”§ è¨­å®šã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### ãƒãƒ¼ãƒˆç•ªå·ã®å¤‰æ›´

`docker-compose.yml`ã®`ports`ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç·¨é›†ï¼š

```yaml
ports:
  - "YOUR_PORT:9997"
```

### GPUè¨­å®šã®å¤‰æ›´

è¤‡æ•°GPUã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€`docker-compose.yml`ã‚’ç·¨é›†ï¼š

```yaml
environment:
  - CUDA_VISIBLE_DEVICES=0,1  # ä½¿ç”¨ã™ã‚‹GPUç•ªå·
```

### ãƒ¡ãƒ¢ãƒªåˆ¶é™ã®è¨­å®š

```yaml
deploy:
  resources:
    limits:
      memory: 8G
```

## ğŸ“Š ä½¿ç”¨æ–¹æ³•

### Xinference Web UI ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹

ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://YOUR_SERVER_IP:9997` ã«ã‚¢ã‚¯ã‚»ã‚¹

### APIçµŒç”±ã§ã®åˆ©ç”¨

```bash
# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
curl http://localhost:9997/v1/models

# ãƒ¢ãƒ‡ãƒ«ã®èµ·å‹•ä¾‹
curl -X POST http://localhost:9997/v1/models \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "vicuna-v1.3",
    "model_size_in_billions": 7
  }'
```

### Python ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ã®åˆ©ç”¨

```python
from xinference.client import Client

client = Client("http://localhost:9997")

# ãƒ¢ãƒ‡ãƒ«ã®èµ·å‹•
model = client.launch_model(
    model_name="vicuna-v1.3",
    model_size_in_billions=7
)

# æ¨è«–ã®å®Ÿè¡Œ
response = model.chat(
    "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ"
)
print(response)
```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### GPUèªè­˜ã•ã‚Œãªã„å ´åˆ

```bash
# GPUç¢ºèª
nvidia-smi

# NVIDIA Container Toolkitç¢ºèª
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu20.04 nvidia-smi
```

### ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹ã‹ã€ã‚ˆã‚Šå¤§ããªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã‚’ä½¿ç”¨ï¼š

```bash
# ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
docker stats xinference-gpu-docker_xinference_1
```

### arm64ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚¨ãƒ©ãƒ¼

`docker-compose.yml`ã§æ˜ç¤ºçš„ã«amd64ã‚’æŒ‡å®šï¼š

```yaml
platform: linux/amd64
```

### ãƒãƒ¼ãƒˆè¡çª

åˆ¥ã®ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨ï¼š

```yaml
ports:
  - "9998:9997"  # 9998ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. SHMã‚µã‚¤ã‚ºã®å¢—åŠ 

```yaml
shm_size: '2g'
```

### 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®æœ€é©åŒ–

SSDã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ä½¿ç”¨ã‚’æ¨å¥¨ï¼š

```yaml
volumes:
  - /mnt/ssd/models:/root/.xinference/cache
```

### 3. ä¸¦åˆ—å‡¦ç†ã®è¨­å®š

```yaml
environment:
  - OMP_NUM_THREADS=4
  - XINFERENCE_MODEL_CACHE_SIZE=10
```

## ğŸ› ï¸ ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§

| ã‚³ãƒãƒ³ãƒ‰ | èª¬æ˜ |
|---------|------|
| `docker-compose up -d` | ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰ |
| `docker-compose down` | ã‚µãƒ¼ãƒãƒ¼åœæ­¢ |
| `docker-compose logs -f` | ãƒ­ã‚°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º |
| `docker-compose ps` | ã‚³ãƒ³ãƒ†ãƒŠçŠ¶æ…‹ç¢ºèª |
| `docker-compose restart` | ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹• |
| `docker-compose pull` | ã‚¤ãƒ¡ãƒ¼ã‚¸æ›´æ–° |

## ğŸ†˜ ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆï¼š

1. [Issues](https://github.com/ShunsukeTamura06/xinference-gpu-docker/issues) ã§æ—¢å­˜ã®å•é¡Œã‚’ç¢ºèª
2. æ–°ã—ã„Issueã‚’ä½œæˆï¼ˆãƒ­ã‚°ã¨ç’°å¢ƒæƒ…å ±ã‚’å«ã‚ã‚‹ï¼‰
3. [Xinferenceå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://inference.readthedocs.io/) ã‚’å‚ç…§

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚„Issueã¯æ­“è¿ã—ã¾ã™ï¼