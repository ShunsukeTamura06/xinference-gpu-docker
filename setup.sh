#!/bin/bash

set -e

echo "ğŸš€ Xinference GPU Docker ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹ï¼ˆT4G GPUå¯¾å¿œï¼‰"

# T4G GPUç’°å¢ƒç¢ºèª
echo "ğŸ”§ T4G GPUç’°å¢ƒç¢ºèªä¸­..."
if command -v nvcc &> /dev/null; then
    echo "âœ… CUDA ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:"
    nvcc --version
    echo ""
else
    echo "âŒ CUDA ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã€‚CUDA 12.9ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    exit 1
fi

# å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
echo "ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆä¸­..."
mkdir -p models logs

# NVIDIA Container Toolkitã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
echo "ğŸ”§ NVIDIA Container Toolkitç¢ºèªä¸­..."
if ! command -v nvidia-container-runtime &> /dev/null; then
    echo "âŒ NVIDIA Container ToolkitãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
    
    # ãƒ—ãƒ­ã‚­ã‚·ç’°å¢ƒã§ã®curlè¨­å®š
    PROXY_ARGS=""
    if [ -n "$HTTP_PROXY" ]; then
        PROXY_ARGS="--proxy $HTTP_PROXY"
    fi
    
    # GPGã‚­ãƒ¼ã®è¿½åŠ 
    curl $PROXY_ARGS -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
    
    # ãƒªãƒã‚¸ãƒˆãƒªã®è¿½åŠ 
    curl $PROXY_ARGS -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
    
    # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’aptç”¨ã«è¿½åŠ 
    if [ -n "$HTTP_PROXY" ]; then
        echo "Acquire::http::Proxy \"$HTTP_PROXY\";" | sudo tee /etc/apt/apt.conf.d/01proxy
        echo "Acquire::https::Proxy \"$HTTPS_PROXY\";" | sudo tee -a /etc/apt/apt.conf.d/01proxy
    fi
    
    # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æ›´æ–°ã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    sudo apt update
    sudo apt install -y nvidia-container-toolkit
    
    # Dockerãƒ‡ãƒ¼ãƒ¢ãƒ³ã®å†èµ·å‹•
    sudo systemctl restart docker
    
    echo "âœ… NVIDIA Container Toolkitã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†"
else
    echo "âœ… NVIDIA Container Toolkitã¯æ—¢ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã™"
fi

# T4G GPUç¢ºèª
echo "ğŸ–¥ï¸  T4G GPUç¢ºèªä¸­..."
nvidia-smi
echo ""

# CUDAãƒ‘ã‚¹ç¢ºèª
echo "ğŸ“š CUDA ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª..."
if [ -d "/usr/local/cuda" ]; then
    echo "âœ… CUDA ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ã‚¹: /usr/local/cuda"
    ls -la /usr/local/cuda/bin/nvcc
else
    echo "âŒ /usr/local/cuda ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    echo "CUDA 12.9ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
    exit 1
fi

# Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã®æ§‹ç¯‰ï¼ˆARM64ãƒã‚¤ãƒ†ã‚£ãƒ–ï¼‰
echo "ğŸ³ ARM64 Dockerã‚¤ãƒ¡ãƒ¼ã‚¸æ§‹ç¯‰ä¸­..."
echo "   â„¹ï¸  T4G GPUç”¨ã®ARM64ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ§‹ç¯‰ã—ã¾ã™"
docker compose build

echo "ğŸ‰ T4G GPUç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼"
echo ""
echo "ğŸš€ Xinferenceã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã™ã‚‹ã«ã¯:"
echo "   docker compose up -d"
echo ""
echo "ğŸ“Š åˆå›èµ·å‹•æ™‚ã®ãƒ­ã‚°ã‚’ç¢ºèªã™ã‚‹ã«ã¯:"
echo "   docker compose logs -f xinference"
echo ""
echo "â„¹ï¸  åˆå›èµ·å‹•æ™‚ã¯ä»¥ä¸‹ã®å‡¦ç†ã®ãŸã‚æ•°åˆ†ã‹ã‹ã‚Šã¾ã™:"
echo "   - ARM64ç”¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
echo "   - PyTorchï¼ˆCUDA 12.xå¯¾å¿œï¼‰ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
echo "   - CUDAç’°å¢ƒã®è¨­å®š"
echo "   é€²è¡ŒçŠ¶æ³ã¯ãƒ­ã‚°ã§ç¢ºèªã§ãã¾ã™"
echo ""
echo "ğŸŒ ã‚µãƒ¼ãƒãƒ¼ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹:"
echo "   http://localhost:9997"
echo ""
echo "ğŸ”§ CUDAå‹•ä½œç¢ºèª:"
echo "   èµ·å‹•å¾Œã€ãƒ­ã‚°ã§ 'CUDA available: True' ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
echo ""
echo "ğŸ›‘ ã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã™ã‚‹ã«ã¯:"
echo "   docker compose down"